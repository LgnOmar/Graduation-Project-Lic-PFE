{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83236bc4",
   "metadata": {},
   "source": [
    "# JibJob Recommender System - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the data used for the JibJob recommendation system, including user profiles, job listings, and their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = str(Path().absolute().parent)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from jibjob_recommender_system.data_handling.data_loader import DataLoader\n",
    "from jibjob_recommender_system.config.config_loader import ConfigLoader\n",
    "\n",
    "# Set up visualization settings\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(project_root, 'jibjob_recommender_system', 'config', 'settings.yaml')\n",
    "config = ConfigLoader.load_config(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f13a97",
   "metadata": {},
   "source": [
    "## 1. Loading and Examining Data\n",
    "\n",
    "First, let's load the data and examine its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths - adjust based on your data location\n",
    "data_dir = os.path.join(project_root, 'sample_data')\n",
    "\n",
    "# Create data loader\n",
    "data_loader = DataLoader(config)\n",
    "\n",
    "# Load data\n",
    "data_dict = data_loader.load_data(data_dir)\n",
    "\n",
    "# Extract DataFrames\n",
    "users_df = data_dict.get('users')\n",
    "jobs_df = data_dict.get('jobs')\n",
    "job_applications_df = data_dict.get('job_applications')\n",
    "categories_df = data_dict.get('categories')\n",
    "\n",
    "print(f\"Users data shape: {users_df.shape if users_df is not None else 'Not available'}\")\n",
    "print(f\"Jobs data shape: {jobs_df.shape if jobs_df is not None else 'Not available'}\")\n",
    "print(f\"Job applications data shape: {job_applications_df.shape if job_applications_df is not None else 'Not available'}\")\n",
    "print(f\"Categories data shape: {categories_df.shape if categories_df is not None else 'Not available'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf86d8",
   "metadata": {},
   "source": [
    "### 1.1 Exploring User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display user data sample\n",
    "if users_df is not None:\n",
    "    print(\"Sample of user data:\")\n",
    "    display(users_df.head())\n",
    "    \n",
    "    # Distribution of user types\n",
    "    user_type_counts = users_df['user_type'].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=user_type_counts.index, y=user_type_counts.values)\n",
    "    plt.title('Distribution of User Types')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('User Type')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extract professionals for further analysis\n",
    "    professionals = users_df[users_df['user_type'] == 'professional']\n",
    "    \n",
    "    # Analyze categories distribution for professionals\n",
    "    if 'categories' in professionals.columns:\n",
    "        # Flatten categories list\n",
    "        all_categories = []\n",
    "        for categories in professionals['categories']:\n",
    "            if isinstance(categories, list):\n",
    "                all_categories.extend(categories)\n",
    "        \n",
    "        category_counts = pd.Series(all_categories).value_counts().head(10)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=category_counts.values, y=category_counts.index)\n",
    "        plt.title('Top 10 Categories Among Professionals')\n",
    "        plt.xlabel('Count')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"User data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e6b6f5",
   "metadata": {},
   "source": [
    "### 1.2 Exploring Job Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb01498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display job data sample\n",
    "if jobs_df is not None:\n",
    "    print(\"Sample of job data:\")\n",
    "    display(jobs_df.head())\n",
    "    \n",
    "    # Analyze categories distribution for jobs\n",
    "    if 'categories' in jobs_df.columns:\n",
    "        # Flatten categories list\n",
    "        all_job_categories = []\n",
    "        for categories in jobs_df['categories']:\n",
    "            if isinstance(categories, list):\n",
    "                all_job_categories.extend(categories)\n",
    "        \n",
    "        job_category_counts = pd.Series(all_job_categories).value_counts().head(10)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x=job_category_counts.values, y=job_category_counts.index)\n",
    "        plt.title('Top 10 Categories Among Jobs')\n",
    "        plt.xlabel('Count')\n",
    "        plt.show()\n",
    "    \n",
    "    # Analyze job distribution by employer\n",
    "    if 'employer_id' in jobs_df.columns:\n",
    "        employer_job_counts = jobs_df['employer_id'].value_counts().head(10)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=employer_job_counts.index, y=employer_job_counts.values)\n",
    "        plt.title('Number of Jobs Posted by Top 10 Employers')\n",
    "        plt.ylabel('Number of Jobs')\n",
    "        plt.xlabel('Employer ID')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Job data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382ae0e",
   "metadata": {},
   "source": [
    "### 1.3 Exploring Job Applications (Interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display job applications data sample\n",
    "if job_applications_df is not None:\n",
    "    print(\"Sample of job applications data:\")\n",
    "    display(job_applications_df.head())\n",
    "    \n",
    "    # Count applications by user\n",
    "    user_application_counts = job_applications_df['user_id'].value_counts()\n",
    "    \n",
    "    # Plot distribution of applications per user\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(user_application_counts, bins=30, kde=True)\n",
    "    plt.title('Distribution of Number of Applications per User')\n",
    "    plt.xlabel('Number of Applications')\n",
    "    plt.ylabel('Count of Users')\n",
    "    plt.show()\n",
    "    \n",
    "    # Count applications by job\n",
    "    job_application_counts = job_applications_df['job_id'].value_counts()\n",
    "    \n",
    "    # Plot top 20 jobs by applications\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    top_jobs = job_application_counts.head(20)\n",
    "    sns.barplot(x=top_jobs.index, y=top_jobs.values)\n",
    "    plt.title('Top 20 Jobs by Application Count')\n",
    "    plt.ylabel('Number of Applications')\n",
    "    plt.xlabel('Job ID')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Job applications data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3311489",
   "metadata": {},
   "source": [
    "## 2. Geographical Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot geographical distribution of users and jobs\n",
    "if users_df is not None and 'latitude' in users_df.columns and 'longitude' in users_df.columns:\n",
    "    professionals = users_df[users_df['user_type'] == 'professional']\n",
    "    \n",
    "    # Create map for professionals\n",
    "    fig = px.scatter_mapbox(\n",
    "        professionals,\n",
    "        lat='latitude',\n",
    "        lon='longitude',\n",
    "        hover_name='user_id',\n",
    "        color_discrete_sequence=[\"blue\"],\n",
    "        zoom=3,\n",
    "        title='Geographical Distribution of Professionals'\n",
    "    )\n",
    "    \n",
    "    # Add jobs to the map if available\n",
    "    if jobs_df is not None and 'latitude' in jobs_df.columns and 'longitude' in jobs_df.columns:\n",
    "        job_layer = px.scatter_mapbox(\n",
    "            jobs_df,\n",
    "            lat='latitude',\n",
    "            lon='longitude',\n",
    "            hover_name='job_id',\n",
    "            color_discrete_sequence=[\"red\"],\n",
    "        ).data[0]\n",
    "        job_layer.name = 'Jobs'\n",
    "        fig.add_trace(job_layer)\n",
    "    \n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0}, height=600)\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Location data not available for mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cfd25",
   "metadata": {},
   "source": [
    "## 3. Category and Skills Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze overlap between user and job categories\n",
    "if users_df is not None and jobs_df is not None and \\\n",
    "   'categories' in users_df.columns and 'categories' in jobs_df.columns:\n",
    "    \n",
    "    # Get all unique categories from users\n",
    "    user_categories = set()\n",
    "    for cat_list in users_df['categories']:\n",
    "        if isinstance(cat_list, list):\n",
    "            user_categories.update(cat_list)\n",
    "    \n",
    "    # Get all unique categories from jobs\n",
    "    job_categories = set()\n",
    "    for cat_list in jobs_df['categories']:\n",
    "        if isinstance(cat_list, list):\n",
    "            job_categories.update(cat_list)\n",
    "    \n",
    "    # Find overlap and unique categories\n",
    "    common_categories = user_categories.intersection(job_categories)\n",
    "    user_only_categories = user_categories - job_categories\n",
    "    job_only_categories = job_categories - user_categories\n",
    "    \n",
    "    # Create Venn diagram data\n",
    "    venn_data = [\n",
    "        len(common_categories),\n",
    "        len(user_only_categories),\n",
    "        len(job_only_categories)\n",
    "    ]\n",
    "    \n",
    "    # Print category overlap statistics\n",
    "    print(f\"Total unique categories across users and jobs: {len(user_categories.union(job_categories))}\")\n",
    "    print(f\"Categories shared between users and jobs: {len(common_categories)}\")\n",
    "    print(f\"Categories unique to users: {len(user_only_categories)}\")\n",
    "    print(f\"Categories unique to jobs: {len(job_only_categories)}\")\n",
    "    \n",
    "    # List top common categories\n",
    "    print(\"\\nSome common categories:\")\n",
    "    for cat in list(common_categories)[:10]:  # Show up to 10\n",
    "        print(f\"- {cat}\")\n",
    "else:\n",
    "    print(\"Categories data not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a3ce5",
   "metadata": {},
   "source": [
    "## 4. Generating Sample Embeddings for Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b349c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for generating embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def generate_text_embeddings(texts, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "    \"\"\"Generate embeddings for a list of texts.\"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(texts)\n",
    "    return embeddings\n",
    "\n",
    "# Generate sample embeddings for job titles\n",
    "if jobs_df is not None and 'title' in jobs_df.columns:\n",
    "    # Take a small sample for demonstration\n",
    "    sample_jobs = jobs_df.head(5)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    sample_titles = sample_jobs['title'].tolist()\n",
    "    try:\n",
    "        embeddings = generate_text_embeddings(sample_titles)\n",
    "        \n",
    "        # Display embedding dimensions\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        \n",
    "        # Visualize first two dimensions\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
    "        \n",
    "        # Label each point with job title\n",
    "        for i, title in enumerate(sample_titles):\n",
    "            plt.annotate(title, (embeddings[i, 0], embeddings[i, 1]))\n",
    "            \n",
    "        plt.title('2D Visualization of Job Title Embeddings')\n",
    "        plt.xlabel('Dimension 1')\n",
    "        plt.ylabel('Dimension 2')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate embeddings: {e}\")\n",
    "else:\n",
    "    print(\"Job title data not available for embedding generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d17349",
   "metadata": {},
   "source": [
    "## 5. Analyzing Data for Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze interactions for recommendation patterns\n",
    "if job_applications_df is not None and jobs_df is not None and 'categories' in jobs_df.columns:\n",
    "    # Merge applications with job data to get category information\n",
    "    merged_data = job_applications_df.merge(jobs_df, on='job_id', how='left')\n",
    "    \n",
    "    # Analyze category distribution in applications\n",
    "    applied_categories = []\n",
    "    for _, row in merged_data.iterrows():\n",
    "        if isinstance(row.get('categories'), list):\n",
    "            applied_categories.extend(row['categories'])\n",
    "    \n",
    "    # Count category frequencies\n",
    "    applied_category_counts = pd.Series(applied_categories).value_counts().head(15)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=applied_category_counts.index, y=applied_category_counts.values)\n",
    "    plt.title('Top 15 Categories in Job Applications')\n",
    "    plt.ylabel('Application Count')\n",
    "    plt.xlabel('Category')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze user application patterns\n",
    "    user_job_counts = merged_data.groupby('user_id').size().reset_index(name='application_count')\n",
    "    \n",
    "    # Plot user application frequency distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(user_job_counts['application_count'], bins=30, kde=True)\n",
    "    plt.title('Distribution of Applications per User')\n",
    "    plt.xlabel('Number of Applications')\n",
    "    plt.ylabel('Count of Users')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze category consistency of users\n",
    "    # For each user, get all their applications and check category overlap\n",
    "    user_category_consistency = {}\n",
    "    \n",
    "    for user_id, group in merged_data.groupby('user_id'):\n",
    "        if len(group) < 2:  # Skip users with fewer than 2 applications\n",
    "            continue\n",
    "            \n",
    "        # Get all categories for this user's applications\n",
    "        all_cats = set()\n",
    "        cat_counts = {}\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            if isinstance(row.get('categories'), list):\n",
    "                for cat in row['categories']:\n",
    "                    all_cats.add(cat)\n",
    "                    cat_counts[cat] = cat_counts.get(cat, 0) + 1\n",
    "        \n",
    "        # Calculate consistency score (average frequency of categories)\n",
    "        if len(all_cats) > 0:\n",
    "            consistency = sum(cat_counts.values()) / (len(all_cats) * len(group))\n",
    "            user_category_consistency[user_id] = consistency\n",
    "    \n",
    "    # Plot distribution of consistency scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(list(user_category_consistency.values()), bins=20, kde=True)\n",
    "    plt.title('Distribution of Category Consistency Across User Applications')\n",
    "    plt.xlabel('Consistency Score (1.0 = perfectly consistent)')\n",
    "    plt.ylabel('Count of Users')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Job application and category data not available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06668f16",
   "metadata": {},
   "source": [
    "## 6. Dataset Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14925920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for the dataset\n",
    "summary = {}\n",
    "\n",
    "# User statistics\n",
    "if users_df is not None:\n",
    "    summary['total_users'] = len(users_df)\n",
    "    if 'user_type' in users_df.columns:\n",
    "        summary['professional_count'] = len(users_df[users_df['user_type'] == 'professional'])\n",
    "        summary['employer_count'] = len(users_df[users_df['user_type'] == 'employer'])\n",
    "\n",
    "# Job statistics\n",
    "if jobs_df is not None:\n",
    "    summary['total_jobs'] = len(jobs_df)\n",
    "    if 'employer_id' in jobs_df.columns:\n",
    "        summary['unique_employers_with_jobs'] = jobs_df['employer_id'].nunique()\n",
    "\n",
    "# Application statistics\n",
    "if job_applications_df is not None:\n",
    "    summary['total_applications'] = len(job_applications_df)\n",
    "    summary['users_with_applications'] = job_applications_df['user_id'].nunique()\n",
    "    summary['jobs_with_applications'] = job_applications_df['job_id'].nunique()\n",
    "\n",
    "# Category statistics\n",
    "category_sets = {}\n",
    "if users_df is not None and 'categories' in users_df.columns:\n",
    "    user_cats = set()\n",
    "    for cats in users_df['categories']:\n",
    "        if isinstance(cats, list):\n",
    "            user_cats.update(cats)\n",
    "    category_sets['user_categories'] = user_cats\n",
    "\n",
    "if jobs_df is not None and 'categories' in jobs_df.columns:\n",
    "    job_cats = set()\n",
    "    for cats in jobs_df['categories']:\n",
    "        if isinstance(cats, list):\n",
    "            job_cats.update(cats)\n",
    "    category_sets['job_categories'] = job_cats\n",
    "\n",
    "if 'user_categories' in category_sets and 'job_categories' in category_sets:\n",
    "    summary['unique_user_categories'] = len(category_sets['user_categories'])\n",
    "    summary['unique_job_categories'] = len(category_sets['job_categories'])\n",
    "    summary['overlapping_categories'] = len(category_sets['user_categories'] & category_sets['job_categories'])\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n===== Dataset Summary =====\\n\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Create summary dataframe for visualization\n",
    "summary_df = pd.DataFrame(list(summary.items()), columns=['Metric', 'Value'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "summary_plot = sns.barplot(data=summary_df, x='Metric', y='Value')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Dataset Summary Statistics')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7b90d",
   "metadata": {},
   "source": [
    "## 7. Conclusions and Next Steps\n",
    "\n",
    "Based on the above analysis, we can draw the following conclusions and plan the next steps:\n",
    "\n",
    "**Conclusions:**\n",
    "* [This will be filled in after running the notebook with actual data]\n",
    "\n",
    "**Next Steps:**\n",
    "1. Feature engineering based on the insights from this analysis\n",
    "2. Build a graph representation of users and jobs with appropriate edge weights\n",
    "3. Train the GCN model with the structure identified above\n",
    "4. Evaluate the model using the metrics defined in the evaluation module\n",
    "5. Fine-tune the recommendation approach based on evaluation results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
